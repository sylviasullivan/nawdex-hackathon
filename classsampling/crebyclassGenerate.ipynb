{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of cloud-class-stratified CRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%reset  # Do this to make sure we have the max memory possible\n",
    "#%whos\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "georgedir = '/pf/b/b380796/scratch/hackathon/george/'\n",
    "nicoledir = '/scratch/b/b380490/hackathon/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up da dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying out this dask thing from Aiko's GitHub repository :p\n",
    "from tempfile import NamedTemporaryFile, TemporaryDirectory # Creating temporary Files/Dirs\n",
    "import dask # Distributed data libary\n",
    "from dask_jobqueue import SLURMCluster # Setting up distributed memories via slurm\n",
    "from distributed import Client, progress, wait # Libaray to orchestrate distributed resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some user specific variables\n",
    "account_name = 'bb1018'\n",
    "partition = 'compute'\n",
    "job_name = 'sylviaCRE' # Job name that is submitted via sbatch\n",
    "memory = '64GiB' # Max memory per node that is going to be used - this depends on the partition\n",
    "cores = 48 # Max number of cores per that are reserved - also partition dependent\n",
    "walltime = '01:00:00' #'12:00:00' # Walltime - also partition dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pf/b/b380459/conda-envs/Nawdex-Hackathon/lib/python3.8/site-packages/distributed/node.py:151: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 45039 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "scratch_dir = '/scratch/b/b380873/' # Define the users scratch dir\n",
    "# Create a temp directory where the output of distributed cluster will be written to, after this notebook\n",
    "# is closed the temp directory will be closed\n",
    "dask_scratch_dir = TemporaryDirectory(dir=scratch_dir, prefix=job_name)\n",
    "cluster = SLURMCluster(memory=memory,\n",
    "                       cores=cores,\n",
    "                       project=account_name,\n",
    "                       walltime=walltime,\n",
    "                       queue=partition,\n",
    "                       name=job_name,\n",
    "                       processes=8,\n",
    "                       scheduler_options={'dashboard_address': ':12435'},\n",
    "                       local_directory=dask_scratch_dir.name,\n",
    "                       job_extra=[f'-J {job_name}', \n",
    "                                  f'-D {dask_scratch_dir.name}',\n",
    "                                  f'--begin=now',\n",
    "                                  f'--output={dask_scratch_dir.name}/LOG_cluster.%j.o',\n",
    "                                  f'--output={dask_scratch_dir.name}/LOG_cluster.%j.o'\n",
    "                                 ],\n",
    "                       interface='ib0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env bash\n",
      "\n",
      "#SBATCH -J dask-worker\n",
      "#SBATCH -p compute\n",
      "#SBATCH -A bb1018\n",
      "#SBATCH -n 1\n",
      "#SBATCH --cpus-per-task=48\n",
      "#SBATCH --mem=64G\n",
      "#SBATCH -t 01:00:00\n",
      "#SBATCH -J sylviaCRE\n",
      "#SBATCH -D /scratch/b/b380873/sylviaCREdbjiy75r\n",
      "#SBATCH --begin=now\n",
      "#SBATCH --output=/scratch/b/b380873/sylviaCREdbjiy75r/LOG_cluster.%j.o\n",
      "#SBATCH --output=/scratch/b/b380873/sylviaCREdbjiy75r/LOG_cluster.%j.o\n",
      "\n",
      "JOB_ID=${SLURM_JOB_ID%;*}\n",
      "\n",
      "/pf/b/b380459/conda-envs/Nawdex-Hackathon/bin/python3 -m distributed.cli.dask_worker tcp://10.50.40.19:37142 --nthreads 6 --nprocs 8 --memory-limit 8.59GB --name name --nanny --death-timeout 60 --local-directory /scratch/b/b380873/sylviaCREdbjiy75r --interface ib0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cluster.job_script())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a132000bad4c3db1f10a53242a6d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>sylviaCRE</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n    .daâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster.scale(jobs=1)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://10.50.40.19:37142</li>\n",
       "  <li><b>Dashboard: </b><a href='http://10.50.40.19:45039/status' target='_blank'>http://10.50.40.19:45039/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.50.40.19:37142' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask_client = Client(cluster)\n",
    "dask_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Pile all cloud classes and all their values, not only statistics, into the same dataframe\n",
    "Memory errors generated..."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Method 1: Filter the cloud radiative effects by class. Store all values, all classes in a single dataframe (B_df). \n",
    "    # For initial setup, generate random cloud radiative effects with dims [ncells, timesteps]\n",
    "    #CRE = np.random.randint(low=-180,high=180,size=(ncells,timesteps))\n",
    "    \n",
    "lbls = ['Cloud class','Resolution','LWCRE_toa','LWCRE_atm','LWCRE_sfc','SWCRE_toa','SWCRE_atm','SWCRE_sfc']\n",
    "B_df = pd.DataFrame(columns=lbls)\n",
    "resolutions = ['5','2'] # '80','40','20','10',\n",
    "for res in resolutions:\n",
    "    print(res)\n",
    "    # Read in the cloud classifications and radiative variables for this resolution.\n",
    "    fi = xr.open_dataset(georgedir + 'cloud_class_array_thres10p_' + res + 'km_alltimesteps_v3.nc')\n",
    "    cc = xr.open_zarr(nicoledir + 'nawdexnwp-' + res + 'km-mis-0001_cre_alltimesteps_oceanmask_applied.zarr')\n",
    "    classes = fi['clch']\n",
    "    \n",
    "    # Set the cloud class, resolution, and radiative values.     \n",
    "    for cloud_class in np.arange(nclasses):\n",
    "        print(cloud_class)\n",
    "        # Extract the cloud class of interest. Generate a mask to extract the non-nan values thereafter.\n",
    "        B2 = cc.where(classes == cloud_class+1)\n",
    "        arr = B2.crelw_toa.values\n",
    "        mask = ~np.isnan(arr)\n",
    "        val = np.array([np.array([class_names[cloud_class]]*np.sum(mask)).T, (np.ones(np.sum(mask))*int(res)).T,\n",
    "                     B2.crelw_toa.values[mask].T, B2.crelw_atm.values[mask].T, B2.crelw_sfc.values[mask].T,\n",
    "                     B2.cresw_toa.values[mask].T, B2.cresw_atm.values[mask].T, B2.cresw_sfc.values[mask].T])\n",
    "        B_df = B_df.append(pd.DataFrame(val.T,columns=lbls),ignore_index=True)\n",
    "\n",
    "# Save the occurrence dataframe to a pickle\n",
    "B_df.to_pickle('cre_all_classes.pkl')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Save the occurrence dataframe in a pickle (or load it).\n",
    "#B_df.to_pickle('cre_by_cloud_class.pkl')\n",
    "#B_df = pd.read_pickle('cre_by_cloud_class.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Pile a single cloud class and all its values, not only statistics, into the same dataframe\n",
    "From the memory errors above, we need to find some way to split the problem better. Here the strategy was to save each class in a separate dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "80\n",
      "40\n",
      "20\n",
      "10\n",
      "5\n",
      "2\n",
      "2\n",
      "80\n",
      "40\n",
      "20\n",
      "10\n",
      "5\n",
      "2\n",
      "3\n",
      "80\n",
      "40\n",
      "20\n",
      "10\n",
      "5\n",
      "2\n",
      "4\n",
      "80\n",
      "40\n",
      "20\n",
      "10\n",
      "5\n",
      "2\n",
      "5\n",
      "80\n",
      "40\n",
      "20\n",
      "10\n",
      "5\n",
      "2\n",
      "6\n",
      "80\n",
      "40\n",
      "20\n",
      "10\n",
      "5\n",
      "2\n",
      "7\n",
      "80\n",
      "40\n",
      "20\n",
      "10\n",
      "5\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Method 2: Filter the cloud radiative effects by class. Store all values for a single class in a single dataframe.\n",
    "nclasses = 8\n",
    "lbls = ['Cloud class','Resolution','LWCRE_toa','LWCRE_atm','LWCRE_sfc','SWCRE_toa','SWCRE_atm','SWCRE_sfc']\n",
    "resolutions = ['80','40','20','10','5','2']\n",
    "class_names = ['HI','MED','LO','H-M','M-L','H-L','H-M-L','Clear-sky']\n",
    "\n",
    "# For each cloud class, iterate over the resolutions and extract its CRE values. \n",
    "# Save these in a dataframe and then delete.\n",
    "for cloud_class in np.arange(1,nclasses):\n",
    "    print(cloud_class)\n",
    "    \n",
    "    # Reinitialize the dataframe to a clean one for each class.\n",
    "    B_df = pd.DataFrame(columns=lbls)\n",
    "    \n",
    "    for res in resolutions:\n",
    "        print(res)\n",
    "    \n",
    "        # Read in the cloud classifications and radiative variables for this resolution.\n",
    "        fi = xr.open_dataset(georgedir + 'cloud_class_array_thres10p_' + res + 'km_alltimesteps_v3.nc')\n",
    "        cc = xr.open_zarr(nicoledir + 'nawdexnwp-' + res + 'km-mis-0001_cre_alltimesteps_oceanmask_applied.zarr')\n",
    "        classes = fi['clch']\n",
    "        \n",
    "        # Extract the cloud class of interest. Generate a mask to extract the non-nan values thereafter.\n",
    "        B2 = cc.where(classes == cloud_class+1)\n",
    "        arr = B2.crelw_toa.values\n",
    "        mask = ~np.isnan(arr)\n",
    "        val = np.array([(np.ones(np.sum(mask))*int(cloud_class+1)).T, (np.ones(np.sum(mask))*int(res)).T,\n",
    "                     B2.crelw_toa.values[mask].T, B2.crelw_atm.values[mask].T, B2.crelw_sfc.values[mask].T,\n",
    "                     B2.cresw_toa.values[mask].T, B2.cresw_atm.values[mask].T, B2.cresw_sfc.values[mask].T])\n",
    "        B_df = B_df.append(pd.DataFrame(val.T,columns=lbls),ignore_index=True)\n",
    "                        \n",
    "    # Save the CRE dataframe in a pickle.                     \n",
    "    B_df.to_pickle('cre_class' + str(cloud_class+1) + '.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3: Pile a single cloud class and only its statistics into the same dataframe\n",
    "From the memory errors above, we need to find some way to split the problem better. Here the strategy was to save only the relevant statistics per cloud class in a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "80\n",
      "40\n",
      "20\n",
      "10\n",
      "5\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Method 3: Filter the cloud radiative effects by class. Store only the percentiles / stats of all these values (B_df). \n",
    "nclasses = 8\n",
    "resolutions = ['80','40','20','10','5','2']\n",
    "class_names = ['HI','MED','LO','H-M','M-L','H-L','H-M-L','Clear-sky']\n",
    "lbls = ['Cloud class','Resolution','LWCRE_toa_p2','LWCRE_toa_p25','LWCRE_toa_med','LWCRE_toa_p75','LWCRE_toa_p98',\\\n",
    "        'LWCRE_atm_p2','LWCRE_atm_p25','LWCRE_atm_med','LWCRE_atm_p75','LWCRE_atm_p98',\\\n",
    "        'LWCRE_sfc_p2','LWCRE_sfc_p25','LWCRE_sfc_med','LWCRE_sfc_p75','LWCRE_sfc_p98',\\\n",
    "        'SWCRE_toa_p2','SWCRE_toa_p25','SWCRE_toa_med','SWCRE_toa_p75','SWCRE_toa_p98',\\\n",
    "        'SWCRE_atm_p2','SWCRE_atm_p25','SWCRE_atm_med','SWCRE_atm_p75','SWCRE_atm_p98',\\\n",
    "        'SWCRE_sfc_p2','SWCRE_sfc_p25','SWCRE_sfc_med','SWCRE_sfc_p75','SWCRE_sfc_p98']\n",
    "B_df = pd.DataFrame(columns=lbls)\n",
    "\n",
    "# Define a function that returns a list of statistics for an xarray field.\n",
    "def stats(field):\n",
    "    return [np.nanpercentile(field,2), np.nanpercentile(field,25), np.nanmedian(field), \\\n",
    "            np.nanpercentile(field,75), np.nanpercentile(field,98)]\n",
    "\n",
    "# Iterate over the cloud classes.     \n",
    "for cloud_class in np.arange(7,8): #np.arange(nclasses):\n",
    "    print(cloud_class)\n",
    "    \n",
    "    for res in resolutions:\n",
    "        print(res)\n",
    "        # Read in the cloud classifications and radiative variables for this resolution.\n",
    "        fi = xr.open_dataset(georgedir + 'cloud_class_array_thres10p_' + res + 'km_alltimesteps_v3.nc')\n",
    "        cc = xr.open_zarr(nicoledir + 'nawdexnwp-' + res + 'km-mis-0001_cre_alltimesteps_oceanmask_applied.zarr')\n",
    "        classes = fi['clch']\n",
    "    \n",
    "        # Extract the cloud class of interest. Generate a mask to extract the non-nan values thereafter.\n",
    "        B2 = cc.where(classes == cloud_class+1)\n",
    "        val = [[class_names[cloud_class], int(res)] + stats(B2.crelw_toa) + stats(B2.crelw_atm) + \\\n",
    "                stats(B2.crelw_sfc) + stats(B2.cresw_toa) + stats(B2.cresw_atm) + stats(B2.cresw_sfc)]\n",
    "        B_df = B_df.append(pd.DataFrame(data=val,columns=lbls),ignore_index=True)\n",
    "        \n",
    "    # Save the occurrence dataframe in a pickle (or load it).\n",
    "    B_df.to_pickle('crestats_class' + str(cloud_class+1) + '.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nawdex-hackathon",
   "language": "python",
   "name": "nawdex-hackathon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
